{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from smallvggnet import SmallVGGNet\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArgParser Things\n",
    "dataset = \"animals\"\n",
    "plot = \"output/train_conv_val.png\"\n",
    "modelPath = \"output/train_conv_nn.model\"\n",
    "label_bin = \"output/train_conv_nn_lb.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, resize it to 64x64 pixels (the required input\n",
    "\t# spatial dimensions of SmallVGGNet), and store the image in the\n",
    "\t# data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (64, 64))\n",
    "\tdata.append(image)\n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)\n",
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=64, height=64, depth=3,\n",
    "\tclasses=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train for 70 steps, validate on 750 samples\n",
      "Epoch 1/75\n",
      "70/70 [==============================] - 62s 889ms/step - loss: 1.3870 - accuracy: 0.5203 - val_loss: 1.6473 - val_accuracy: 0.3480\n",
      "Epoch 2/75\n",
      "70/70 [==============================] - 52s 746ms/step - loss: 1.0260 - accuracy: 0.5834 - val_loss: 2.2945 - val_accuracy: 0.3147\n",
      "Epoch 3/75\n",
      "70/70 [==============================] - 52s 740ms/step - loss: 0.9079 - accuracy: 0.6064 - val_loss: 1.7899 - val_accuracy: 0.3173\n",
      "Epoch 4/75\n",
      "70/70 [==============================] - 59s 849ms/step - loss: 0.8261 - accuracy: 0.6217 - val_loss: 1.0656 - val_accuracy: 0.4440\n",
      "Epoch 5/75\n",
      "70/70 [==============================] - 64s 914ms/step - loss: 0.7618 - accuracy: 0.6411 - val_loss: 1.3592 - val_accuracy: 0.4027\n",
      "Epoch 6/75\n",
      "70/70 [==============================] - 56s 802ms/step - loss: 0.7443 - accuracy: 0.6434 - val_loss: 0.9807 - val_accuracy: 0.5213\n",
      "Epoch 7/75\n",
      "70/70 [==============================] - 61s 869ms/step - loss: 0.7285 - accuracy: 0.6592 - val_loss: 0.6804 - val_accuracy: 0.6707\n",
      "Epoch 8/75\n",
      "70/70 [==============================] - 62s 887ms/step - loss: 0.7093 - accuracy: 0.6664 - val_loss: 0.6445 - val_accuracy: 0.7013\n",
      "Epoch 9/75\n",
      "70/70 [==============================] - 58s 830ms/step - loss: 0.6894 - accuracy: 0.6677 - val_loss: 0.7398 - val_accuracy: 0.6640\n",
      "Epoch 10/75\n",
      "70/70 [==============================] - 64s 911ms/step - loss: 0.6675 - accuracy: 0.6700 - val_loss: 0.6313 - val_accuracy: 0.7240\n",
      "Epoch 11/75\n",
      "70/70 [==============================] - 62s 890ms/step - loss: 0.6407 - accuracy: 0.6966 - val_loss: 0.6115 - val_accuracy: 0.7227\n",
      "Epoch 12/75\n",
      "70/70 [==============================] - 57s 811ms/step - loss: 0.6522 - accuracy: 0.6961 - val_loss: 0.6689 - val_accuracy: 0.7053\n",
      "Epoch 13/75\n",
      "70/70 [==============================] - 58s 828ms/step - loss: 0.6411 - accuracy: 0.6912 - val_loss: 1.0822 - val_accuracy: 0.6120\n",
      "Epoch 14/75\n",
      "70/70 [==============================] - 56s 800ms/step - loss: 0.6218 - accuracy: 0.6988 - val_loss: 0.6127 - val_accuracy: 0.7053\n",
      "Epoch 15/75\n",
      "70/70 [==============================] - 56s 803ms/step - loss: 0.6282 - accuracy: 0.7002 - val_loss: 0.5952 - val_accuracy: 0.7280\n",
      "Epoch 16/75\n",
      "70/70 [==============================] - 57s 813ms/step - loss: 0.6180 - accuracy: 0.6984 - val_loss: 0.5932 - val_accuracy: 0.7427\n",
      "Epoch 17/75\n",
      "70/70 [==============================] - 55s 779ms/step - loss: 0.6014 - accuracy: 0.7142 - val_loss: 0.7664 - val_accuracy: 0.6893\n",
      "Epoch 18/75\n",
      "70/70 [==============================] - 60s 852ms/step - loss: 0.5956 - accuracy: 0.7047 - val_loss: 0.6736 - val_accuracy: 0.7187\n",
      "Epoch 19/75\n",
      "70/70 [==============================] - 64s 917ms/step - loss: 0.5732 - accuracy: 0.7362 - val_loss: 0.6175 - val_accuracy: 0.7307\n",
      "Epoch 20/75\n",
      "70/70 [==============================] - 58s 825ms/step - loss: 0.5748 - accuracy: 0.7232 - val_loss: 0.6003 - val_accuracy: 0.7307\n",
      "Epoch 21/75\n",
      "70/70 [==============================] - 65s 933ms/step - loss: 0.5800 - accuracy: 0.7178 - val_loss: 0.6122 - val_accuracy: 0.7173\n",
      "Epoch 22/75\n",
      "70/70 [==============================] - 53s 760ms/step - loss: 0.5554 - accuracy: 0.7322 - val_loss: 0.5755 - val_accuracy: 0.7347\n",
      "Epoch 23/75\n",
      "70/70 [==============================] - 55s 790ms/step - loss: 0.5366 - accuracy: 0.7408 - val_loss: 0.5673 - val_accuracy: 0.7560\n",
      "Epoch 24/75\n",
      "70/70 [==============================] - 53s 759ms/step - loss: 0.5623 - accuracy: 0.7299 - val_loss: 0.6033 - val_accuracy: 0.7427\n",
      "Epoch 25/75\n",
      "70/70 [==============================] - 52s 745ms/step - loss: 0.5647 - accuracy: 0.7358 - val_loss: 0.6977 - val_accuracy: 0.7093\n",
      "Epoch 26/75\n",
      "70/70 [==============================] - 52s 740ms/step - loss: 0.5412 - accuracy: 0.7367 - val_loss: 0.5683 - val_accuracy: 0.7613\n",
      "Epoch 27/75\n",
      "70/70 [==============================] - 51s 734ms/step - loss: 0.5539 - accuracy: 0.7304 - val_loss: 0.7068 - val_accuracy: 0.6853\n",
      "Epoch 28/75\n",
      "70/70 [==============================] - 52s 742ms/step - loss: 0.5341 - accuracy: 0.7430 - val_loss: 0.6603 - val_accuracy: 0.7333\n",
      "Epoch 29/75\n",
      "70/70 [==============================] - 54s 765ms/step - loss: 0.5448 - accuracy: 0.7448 - val_loss: 0.6187 - val_accuracy: 0.7587\n",
      "Epoch 30/75\n",
      "70/70 [==============================] - 51s 731ms/step - loss: 0.5252 - accuracy: 0.7574 - val_loss: 0.6173 - val_accuracy: 0.7440\n",
      "Epoch 31/75\n",
      "70/70 [==============================] - 51s 728ms/step - loss: 0.5065 - accuracy: 0.7633 - val_loss: 0.5941 - val_accuracy: 0.7560\n",
      "Epoch 32/75\n",
      "70/70 [==============================] - 51s 729ms/step - loss: 0.5217 - accuracy: 0.7507 - val_loss: 0.6103 - val_accuracy: 0.7560\n",
      "Epoch 33/75\n",
      "70/70 [==============================] - 51s 727ms/step - loss: 0.5119 - accuracy: 0.7570 - val_loss: 0.5674 - val_accuracy: 0.7307\n",
      "Epoch 34/75\n",
      "70/70 [==============================] - 51s 731ms/step - loss: 0.5186 - accuracy: 0.7525 - val_loss: 0.5763 - val_accuracy: 0.7493\n",
      "Epoch 35/75\n",
      "70/70 [==============================] - 51s 725ms/step - loss: 0.5061 - accuracy: 0.7624 - val_loss: 0.7350 - val_accuracy: 0.7227\n",
      "Epoch 36/75\n",
      "70/70 [==============================] - 51s 724ms/step - loss: 0.5065 - accuracy: 0.7674 - val_loss: 0.5867 - val_accuracy: 0.7493\n",
      "Epoch 37/75\n",
      "70/70 [==============================] - 51s 722ms/step - loss: 0.4909 - accuracy: 0.7687 - val_loss: 0.5644 - val_accuracy: 0.7773\n",
      "Epoch 38/75\n",
      "70/70 [==============================] - 51s 722ms/step - loss: 0.5049 - accuracy: 0.7597 - val_loss: 0.7581 - val_accuracy: 0.7160\n",
      "Epoch 39/75\n",
      "70/70 [==============================] - 51s 722ms/step - loss: 0.4869 - accuracy: 0.7651 - val_loss: 0.7095 - val_accuracy: 0.7240\n",
      "Epoch 40/75\n",
      "70/70 [==============================] - 51s 723ms/step - loss: 0.4827 - accuracy: 0.7764 - val_loss: 0.6095 - val_accuracy: 0.7533\n",
      "Epoch 41/75\n",
      "70/70 [==============================] - 51s 722ms/step - loss: 0.4814 - accuracy: 0.7777 - val_loss: 0.6821 - val_accuracy: 0.7307\n",
      "Epoch 42/75\n",
      "70/70 [==============================] - 51s 723ms/step - loss: 0.4850 - accuracy: 0.7692 - val_loss: 0.6749 - val_accuracy: 0.7480\n",
      "Epoch 43/75\n",
      "70/70 [==============================] - 51s 724ms/step - loss: 0.4743 - accuracy: 0.7836 - val_loss: 0.5241 - val_accuracy: 0.7747\n",
      "Epoch 44/75\n",
      "70/70 [==============================] - 51s 723ms/step - loss: 0.4606 - accuracy: 0.7831 - val_loss: 0.6216 - val_accuracy: 0.7427\n",
      "Epoch 45/75\n",
      "70/70 [==============================] - 51s 723ms/step - loss: 0.4666 - accuracy: 0.7764 - val_loss: 0.5441 - val_accuracy: 0.7720\n",
      "Epoch 46/75\n",
      "70/70 [==============================] - 51s 726ms/step - loss: 0.4543 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7880\n",
      "Epoch 47/75\n",
      "70/70 [==============================] - 51s 724ms/step - loss: 0.4463 - accuracy: 0.7926 - val_loss: 0.8768 - val_accuracy: 0.6987\n",
      "Epoch 48/75\n",
      "70/70 [==============================] - 50s 721ms/step - loss: 0.4475 - accuracy: 0.7931 - val_loss: 0.5462 - val_accuracy: 0.7760\n",
      "Epoch 49/75\n",
      "70/70 [==============================] - 51s 724ms/step - loss: 0.4279 - accuracy: 0.8039 - val_loss: 0.7723 - val_accuracy: 0.7227\n",
      "Epoch 50/75\n",
      "70/70 [==============================] - 51s 727ms/step - loss: 0.4433 - accuracy: 0.7944 - val_loss: 1.0334 - val_accuracy: 0.6827\n",
      "Epoch 51/75\n",
      "70/70 [==============================] - 54s 770ms/step - loss: 0.4628 - accuracy: 0.7836 - val_loss: 0.5415 - val_accuracy: 0.7640\n",
      "Epoch 52/75\n",
      "70/70 [==============================] - 55s 789ms/step - loss: 0.4528 - accuracy: 0.7894 - val_loss: 0.9907 - val_accuracy: 0.6733\n",
      "Epoch 53/75\n",
      "70/70 [==============================] - 63s 894ms/step - loss: 0.4480 - accuracy: 0.7958 - val_loss: 0.5948 - val_accuracy: 0.7653\n",
      "Epoch 54/75\n",
      "70/70 [==============================] - 57s 813ms/step - loss: 0.4448 - accuracy: 0.7876 - val_loss: 0.6167 - val_accuracy: 0.7547\n",
      "Epoch 55/75\n",
      "70/70 [==============================] - 58s 828ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5836 - val_accuracy: 0.7680\n",
      "Epoch 56/75\n",
      "70/70 [==============================] - 54s 774ms/step - loss: 0.4291 - accuracy: 0.8075 - val_loss: 0.6714 - val_accuracy: 0.7413\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 54s 773ms/step - loss: 0.4270 - accuracy: 0.8034 - val_loss: 0.6630 - val_accuracy: 0.7627\n",
      "Epoch 58/75\n",
      "70/70 [==============================] - 54s 772ms/step - loss: 0.4545 - accuracy: 0.7958 - val_loss: 0.6238 - val_accuracy: 0.7600\n",
      "Epoch 59/75\n",
      "70/70 [==============================] - 55s 792ms/step - loss: 0.4210 - accuracy: 0.8034 - val_loss: 0.5888 - val_accuracy: 0.7667\n",
      "Epoch 60/75\n",
      "70/70 [==============================] - 60s 860ms/step - loss: 0.4215 - accuracy: 0.8133 - val_loss: 0.6553 - val_accuracy: 0.7613\n",
      "Epoch 61/75\n",
      "70/70 [==============================] - 54s 773ms/step - loss: 0.4115 - accuracy: 0.8161 - val_loss: 1.2626 - val_accuracy: 0.6173\n",
      "Epoch 62/75\n",
      "70/70 [==============================] - 54s 777ms/step - loss: 0.4188 - accuracy: 0.8097 - val_loss: 0.6150 - val_accuracy: 0.7547\n",
      "Epoch 63/75\n",
      "70/70 [==============================] - 53s 761ms/step - loss: 0.4048 - accuracy: 0.8161 - val_loss: 0.6220 - val_accuracy: 0.7613\n",
      "Epoch 64/75\n",
      "70/70 [==============================] - 52s 740ms/step - loss: 0.3809 - accuracy: 0.8269 - val_loss: 0.6474 - val_accuracy: 0.7640\n",
      "Epoch 65/75\n",
      "70/70 [==============================] - 51s 726ms/step - loss: 0.4020 - accuracy: 0.8188 - val_loss: 0.7809 - val_accuracy: 0.7133\n",
      "Epoch 66/75\n",
      "70/70 [==============================] - 53s 757ms/step - loss: 0.4126 - accuracy: 0.8111 - val_loss: 0.6683 - val_accuracy: 0.7480\n",
      "Epoch 67/75\n",
      "70/70 [==============================] - 53s 754ms/step - loss: 0.4000 - accuracy: 0.8291 - val_loss: 0.6042 - val_accuracy: 0.7813\n",
      "Epoch 68/75\n",
      "70/70 [==============================] - 57s 815ms/step - loss: 0.4028 - accuracy: 0.8147 - val_loss: 0.5393 - val_accuracy: 0.7920\n",
      "Epoch 69/75\n",
      "70/70 [==============================] - 57s 811ms/step - loss: 0.4040 - accuracy: 0.8251 - val_loss: 0.5996 - val_accuracy: 0.7627\n",
      "Epoch 70/75\n",
      "70/70 [==============================] - 58s 833ms/step - loss: 0.4110 - accuracy: 0.8129 - val_loss: 1.0058 - val_accuracy: 0.7027\n",
      "Epoch 71/75\n",
      "70/70 [==============================] - 57s 812ms/step - loss: 0.3955 - accuracy: 0.8224 - val_loss: 0.8363 - val_accuracy: 0.6987\n",
      "Epoch 72/75\n",
      "70/70 [==============================] - 70s 995ms/step - loss: 0.3948 - accuracy: 0.8251 - val_loss: 0.8636 - val_accuracy: 0.7240\n",
      "Epoch 73/75\n",
      "70/70 [==============================] - 62s 880ms/step - loss: 0.3832 - accuracy: 0.8350 - val_loss: 0.6154 - val_accuracy: 0.7640\n",
      "Epoch 74/75\n",
      "70/70 [==============================] - 60s 858ms/step - loss: 0.4116 - accuracy: 0.8133 - val_loss: 0.5988 - val_accuracy: 0.7747\n",
      "Epoch 75/75\n",
      "70/70 [==============================] - 60s 862ms/step - loss: 0.3813 - accuracy: 0.8264 - val_loss: 0.8248 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the network\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.69      0.69      0.69       236\n",
      "        dogs       0.72      0.46      0.56       236\n",
      "       panda       0.75      0.97      0.85       278\n",
      "\n",
      "    accuracy                           0.72       750\n",
      "   macro avg       0.72      0.71      0.70       750\n",
      "weighted avg       0.72      0.72      0.71       750\n",
      "\n",
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(plot)\n",
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(modelPath, save_format=\"h5\")\n",
    "f = open(label_bin, \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
